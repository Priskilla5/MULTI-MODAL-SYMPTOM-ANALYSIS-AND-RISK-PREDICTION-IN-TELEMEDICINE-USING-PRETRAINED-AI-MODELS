# ğŸ§  Multi-Modal Symptom Analysis and Risk Prediction in Telemedicine using Pretrained AI Models

![Architecture Diagram](https://i.postimg.cc/YqCNr8wB/main-diagram.png)

## ğŸ©º Project Overview

In todayâ€™s fast-evolving healthcare landscape, remote diagnosis and patient care have become more critical than ever. This project introduces an AI-powered telemedicine solution capable of **analyzing both visual and textual symptoms** to provide **accurate medical condition predictions, risk severity classification, and appropriate health guidance** â€” all powered by cutting-edge pretrained models.

This system enables users to upload **images (e.g., wounds, rashes)** and **describe symptoms via text**, and in return, they receive **diagnostic insights**, **severity assessment**, and **remedies or escalation suggestions**, making healthcare more **accessible, faster, and efficient**.

---

## ğŸš€ Key Features

- ğŸ“· Image analysis using **CLIP**
- ğŸ’¬ Text-based diagnosis with **BioGPT**
- ğŸ§  Conflict resolution using **LLaMA**
- âš ï¸ Severity classification via **BioClinicalBERT**
- ğŸ©¹ Treatment and remedy suggestions via **MediSearch API**
- ğŸŒ Fully integrated **Flutter frontend** and **Flask backend**

---

## ğŸ§  System Architecture

The architecture diagram above outlines the complete flow of data and model interactions.

1. **User Input**:
   - Upload a **medical image**
   - Enter a **brief description of symptoms**

2. **CLIP Model (Image Analysis)**:
   - Processes the image and classifies probable medical conditions.

3. **BioGPT (Textual Analysis)**:
   - Analyzes symptoms text to predict conditions.

4. **LLaMA (Decision Resolver)**:
   - Resolves any conflicts between image and text predictions.

5. **BioClinicalBERT (Severity Classifier)**:
   - Assesses severity as Low, Medium, or High.

6. **MediSearch API (Remedy Engine)**:
   - Suggests remedies for Low/Medium severity.
   - Flags High severity for doctor consultation.

---

## ğŸ’¡ Use Case Scenarios

- Skin rash detection and remedy advice
- Burn or wound image analysis with severity estimate
- Early identification of visible skin infections
- Symptom-based risk prediction (e.g., fever + sore throat)

---

## ğŸ› ï¸ Tech Stack

| Layer        | Tech/Model                                     |
|--------------|------------------------------------------------|
| Frontend     | Flutter (Dart)                                 |
| Backend      | Flask (Python)                                 |
| Image Model  | [CLIP](https://openai.com/research/clip)       |
| Text Model   | [BioGPT](https://huggingface.co/microsoft/BioGPT) |
| Conflict Res.| [LLaMA](https://ai.meta.com/llama/)            |
| Severity Cls.| [BioClinicalBERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT) |
| Remedy API   | MediSearch API                                 |
| Dataset      | Multimodal symptom dataset, `severity_classification_dataset.csv` |

---

## ğŸ“± App Workflow

1. User opens the Flutter app.
2. Uploads image + enters symptom description.
3. Results shown:
   - âœ… Final diagnosis
   - ğŸ“Š Risk level (Low, Medium, High)
   - ğŸ’Š Remedies or âš ï¸ Doctor consultation warning

---

## ğŸ“ˆ Results & Performance

- ğŸ” Accuracy (CLIP + BioGPT Fusion): **~87%**
- ğŸ¯ F1 Score (Severity Classification): **0.91**
- âš¡ Average Inference Time: **< 6 seconds**
- ğŸ˜Š User Satisfaction in pilot: **92%**

---

## ğŸ”® Future Enhancements

- ğŸŒ Multilingual support
- ğŸ¥ EHR system integration
- ğŸ¥ Real-time video input support
- ğŸ§  Federated learning for continuous improvement

---

## ğŸ‘¨â€âš•ï¸ Conclusion

This project is a powerful blend of AI and healthcare, leveraging **pretrained vision and language models** to assist in real-world medical decision-making. It represents a scalable step toward smarter, faster, and more inclusive telemedicine.

---
