# Multi-Modal Symptom Analysis and Risk Prediction in Telemedicine using Pretrained AI Models

![Architecture Diagram](https://i.postimg.cc/YqCNr8wB/main-diagram.png)

##  Project Overview

In today‚Äôs fast-evolving healthcare landscape, remote diagnosis and patient care have become more critical than ever. This project introduces an AI-powered telemedicine solution capable of **analyzing both visual and textual symptoms** to provide **accurate medical condition predictions, risk severity classification, and appropriate health guidance** ‚Äî all powered by cutting-edge pretrained models.

This system enables users to upload **images (e.g., wounds, rashes)** and **describe symptoms via text**, and in return, they receive **diagnostic insights**, **severity assessment**, and **remedies or escalation suggestions**, making healthcare more **accessible, faster, and efficient**.

---

##  Key Features

- üì∑ Image analysis using **CLIP**
- üí¨ Text-based diagnosis with **BioGPT**
- üß† Conflict resolution using **LLaMA**
- ‚ö†Ô∏è Severity classification via **BioClinicalBERT**
- ü©π Treatment and remedy suggestions via **MediSearch API**
- üåê Fully integrated **Flutter frontend** and **Flask backend**

---

##  System Architecture

The architecture diagram above outlines the complete flow of data and model interactions.

1. **User Input**:
   - Upload a **medical image**
   - Enter a **brief description of symptoms**

2. **CLIP Model (Image Analysis)**:
   - Processes the image and classifies probable medical conditions.

3. **BioGPT (Textual Analysis)**:
   - Analyzes symptoms text to predict conditions.

4. **LLaMA (Decision Resolver)**:
   - Resolves any conflicts between image and text predictions.

5. **BioClinicalBERT (Severity Classifier)**:
   - Assesses severity as Low, Medium, or High.

6. **MediSearch API (Remedy Engine)**:
   - Suggests remedies for Low/Medium severity.
   - Flags High severity for doctor consultation.

---

##  Use Case Scenarios

- Skin rash detection and remedy advice
- Burn or wound image analysis with severity estimate
- Early identification of visible skin infections
- Symptom-based risk prediction (e.g., fever + sore throat)

---

## üõ†Ô∏è Tech Stack

| Layer        | Tech/Model                                     |
|--------------|------------------------------------------------|
| Frontend     | Flutter (Dart)                                 |
| Backend      | Flask (Python)                                 |
| Image Model  | [CLIP](https://openai.com/research/clip)       |
| Text Model   | [BioGPT](https://huggingface.co/microsoft/BioGPT) |
| Conflict Res.| [LLaMA](https://ai.meta.com/llama/)            |
| Severity Cls.| [BioClinicalBERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT) |
| Remedy API   | MediSearch API                                 |
| Dataset      | Multimodal symptom dataset, `severity_classification_dataset.csv` |

---

## üì± App Workflow

1. User opens the Flutter app.
2. Uploads image + enters symptom description.
3. Results shown:
   - ‚úÖ Final diagnosis
   - üìä Risk level (Low, Medium, High)
   - üíä Remedies or ‚ö†Ô∏è Doctor consultation warning

---

##  Results & Performance

- üîç Accuracy (CLIP + BioGPT Fusion): **~87%**
- üéØ F1 Score (Severity Classification): **0.91**
- ‚ö° Average Inference Time: **< 6 seconds**
- üòä User Satisfaction in pilot: **92%**

---

##  Future Enhancements

- üåç Multilingual support
- üè• EHR system integration
- üé• Real-time video input support
- üß† Federated learning for continuous improvement

---

## üë®‚Äç‚öïÔ∏è Conclusion

This project is a powerful blend of AI and healthcare, leveraging **pretrained vision and language models** to assist in real-world medical decision-making. It represents a scalable step toward smarter, faster, and more inclusive telemedicine.

---
